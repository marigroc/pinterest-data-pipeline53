{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import regexp_replace\n",
    "\n",
    "display(df_pin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_nulls_to_dataframe_column(dataframe, column, value_to_replace):\n",
    "    '''\n",
    "    Converts matched values in the specified column of the DataFrame to null based on the provided expression.\n",
    "\n",
    "    Parameters:\n",
    "    - dataframe (DataFrame): The PySpark DataFrame to be modified.\n",
    "    - column (str): The name of the column in which values will be replaced with null.\n",
    "    - value_to_replace (str): The expression to identify values in the column that should be replaced with null.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame: The modified DataFrame with specified values replaced by null.\n",
    "    '''\n",
    "    dataframe = dataframe.withColumn(column, when(col(column).like(value_to_replace), None).otherwise(col(column)))\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The code performs a series of data cleaning and transformation operations on the DataFrame df_pin.\n",
    "\n",
    "1. Replace empty entries and entries with no relevant data in specific columns with None.\n",
    "   - Columns and values for replacement are defined in the dictionary columns_and_values_for_null.\n",
    "\n",
    "2. Perform necessary transformations on the 'follower_count' column to ensure every entry is a number.\n",
    "   - Replace 'k' with '000' and 'M' with '000000'.\n",
    "\n",
    "3. Cast selected numeric columns to the correct data type ('double').\n",
    "   - Numeric columns are specified in the list numeric_columns.\n",
    "\n",
    "4. Modify the 'save_location' column to include only the saved location path.\n",
    "   - Remove the prefix 'Local save in '.\n",
    "\n",
    "5. Rename the 'index' column to 'ind'.\n",
    "\n",
    "6. Reorder the DataFrame columns to the desired sequence specified in the new_order list.\n",
    "\n",
    "7. Display the changes using df_pin.show().\n",
    "\n",
    "Note: The add_nulls_to_dataframe_column function is assumed to be defined elsewhere in the codebase.\n",
    "\"\"\"\n",
    "columns_and_values_for_null = {\n",
    "    \"description\": \"No description available%\",\n",
    "    \"follower_count\": \"User Info Error\",\n",
    "    \"image_src\": \"Image src error.\",\n",
    "    \"poster_name\": \"User Info Error\",\n",
    "    \"tag_list\": \"N,o, ,T,a,g,s, ,A,v,a,i,l,a,b,l,e\",\n",
    "    \"title\": \"No Title Data Available\"\n",
    "}\n",
    "\n",
    "# loop through dictionary, calling function with dictionary values as arguments\n",
    "for key, value in columns_and_values_for_null.items():\n",
    "    df_pin = add_nulls_to_dataframe_column(df_pin, key, value)\n",
    "# Perform the necessary transformations on the follower_count to ensure every entry is a number\n",
    "df_pin = df_pin.withColumn(\"follower_count\", regexp_replace(\"follower_count\", \"k\", \"000\"))\n",
    "df_pin = df_pin.withColumn(\"follower_count\", regexp_replace(\"follower_count\", \"M\", \"000000\"))\n",
    "# Define a list of numeric column names\n",
    "numeric_columns = [\"age\", \"downloaded\", \"follower_count\", \"index\"]\n",
    "# Cast numeric columns to the correct data type\n",
    "for column in numeric_columns:\n",
    "    df_pin = df_pin.withColumn(column, col(column).cast(\"double\"))\n",
    "# The save_llocation column to include only the saved location path.\n",
    "df_pin = df_pin.withColumn(\"save_location\", regexp_replace(\"save_location\", \"Local save in \", \"\"))\n",
    "# Rename the index column to ind\n",
    "df_pin = df_pin.withColumnRenamed(\"index\", \"ind\")\n",
    "# Desired new world order:\n",
    "new_order = [\"ind\", \"unique_id\", \"title\", \"description\", \"follower_count\", \"poster_name\", \"tag_list\", \"is_image_or_video\", \"image_src\", \"save_location\", \"category\"]\n",
    "# Enforce the new world order:\n",
    "df_pin = df_pin.select(*[col(column) for column in new_order])\n",
    "# display changes\n",
    "df_pin.show(truncate=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import ArrayType, DoubleType\n",
    "\n",
    "\"\"\"\n",
    "    Process the DataFrame for geographical data.\n",
    "    \n",
    "    Args:\n",
    "    - df_geo (DataFrame): Input DataFrame with geographical data.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame: Processed DataFrame with the following modifications:\n",
    "      1. Created a new column \"coordinates\" with an array of latitude and longitude.\n",
    "      2. Dropped the \"latitude\" and \"longitude\" columns.\n",
    "      3. Converted the \"timestamp\" column into a timestamp data type.\n",
    "      4. A new column order with \"ind\", \"country\", \"coordinates\", and \"timestamp\".\n",
    "    \"\"\"\n",
    "# Create a new column coordinates with an array of latitude and longitude\n",
    "df_geo = df_geo.withColumn(\"coordinates\", array(col(\"latitude\"), col(\"longitude\")))\n",
    "# Drop the longitude and latitude columns\n",
    "df_geo = df_geo.drop(\"latitude\", \"longitude\")\n",
    "# Conver the timestamp column into timestamp data type\n",
    "df_geo.withColumn(\"timestamp\", to_timestamp(\"timestamp\"))\n",
    "# Desired new world order:\n",
    "new_order = [\"ind\", \"country\", \"coordinates\", \"timestamp\"]\n",
    "# Enforce the new world order:\n",
    "df_geo = df_geo.select(*[col(column) for column in new_order])\n",
    "# Show the updated DataFrame\n",
    "df_geo.show(truncate=False)\n",
    "# display changes\n",
    "df_geo.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Transforms the user DataFrame with the following steps:\n",
    "\n",
    "1. Create a new column for the full name by concatenating 'first_name' and 'last_name'.\n",
    "2. Drop the 'first_name' and 'last_name' columns.\n",
    "3. Convert the 'date_joined' column to timestamp data type.\n",
    "4. Define the desired new column order.\n",
    "5. Reorder the DataFrame columns to enforce the new order.\n",
    "6. Display the updated DataFrame.\n",
    "7. Print the schema changes.\n",
    "\n",
    "Parameters:\n",
    "- df_user (DataFrame): The original user DataFrame.\n",
    "\n",
    "Returns:\n",
    "- df_user (DataFrame): The transformed user DataFrame.\n",
    "\"\"\"\n",
    "# create a column for the full name\n",
    "df_user = df_user.withColumn(\"user_name\", concat_ws(\" \", \"first_name\", \"last_name\"))\n",
    "# Drop the longitude and latitude columns\n",
    "df_user = df_user.drop(\"first_name\", \"last_name\")\n",
    "# Conver the timestamp column into timestamp data type\n",
    "df_user.withColumn(\"date_joined\", to_timestamp(\"date_joined\"))\n",
    "# Desired new world order:\n",
    "new_order = [\"ind\", \"user_name\", \"age\", \"date_joined\"]\n",
    "# Enforce the new world order:\n",
    "df_user = df_user.select(*[col(column) for column in new_order])\n",
    "# Show the updated DataFrame\n",
    "df_user.show(truncate=False)\n",
    "# display changes\n",
    "df_user.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
